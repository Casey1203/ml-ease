# HMM模型

隐马尔科夫模型（HMM）可用于标注问题，在语音识别、NLP、生物信息（DNA）、模式识别等领域被实践证明是有效的算法。

## 1. HMM的定义

### 1.1 标记说明

HMM是关于时序的概率模型，描述一个过程：由一个隐藏的马尔科夫链随机生成不可观测的状态随机序列，同时每个状态会产生一个观测，进而形成观测随机序列。

由隐藏的马尔科夫随机生成的状态的序列，称为状态序列（state sequence）。每个状态生成一个观测，形成的观测的序列称为观测序列（observation sequence）。这两个序列的每个位置可以看作一个时刻。

![Image text](https://raw.github.com/Casey1203/ml-ease/master/img/hmm.png)

图中$z_1,z_2\ldots z_{n+1}$是状态序列，$x_1,x_2\ldots x_{n+1}$是观测序列。

HMM由初始状态分布$\pi$，状态转移概率分布$A$以及观测概率分布$B$确定。以三元符号表示，即
$$
\lambda=(A,B,\pi)
$$
接着，定义$Q$是所有可能的状态集合，$N$是可能的状态数。
$$
Q=\{q_1,q_2,\ldots,q_N\}
$$
定义$V$是可能的观测的集合，$M$是可能的观测数。
$$
V=\{v_1,v_2,\ldots,v_M\}
$$
接下来定义状态序列$I$和对应的观测序列$O$，它们的长度都为$T$
$$
I=\{i_1,i_2,\ldots,i_T\} \\
O=\{o_1,o_2,\ldots,o_T\}
$$
状态转移概率分布$A$是一个$N \times N$的矩阵，即$A=\left[a_{ij}\right]_{N\times N}$

其中，$a_{ij}=P(i_{t+1}=q_j|i_t=q_i)$表示$t$时刻处于状态$q_i$的条件下，在$t+1$时刻下转移到了状态$q_j$的概率。

观测概率分布B是一个$N \times M$的矩阵，即$B=\left[b_{i,k}\right]_{N\times M}$

其中，$b_{ik}=P(o_t=v_k|i_k=q_i)$表示在$t$时刻处于状态$q_i$的条件下，生成观测$v_k$的概率。

初始状态分布$\pi$是一个$N\times 1$的向量，其中$\pi_i=P(i_1=q_i)$表示在1时刻处于状态$q_i$的概率。

### 1.2 HMM的两个假设

1. 齐次马尔科夫性假设：假设隐藏的马尔科夫链在任意时刻$t$的状态，只依赖于其前一时刻的状态，与其他时刻的状态及观测无关，也与时刻$t$无关。

$$
P(i_t|i_{t-1},o_{t-1})
$$



1. 观测独立性假设：假设任意时刻的观测，只依赖于该时刻的马尔科夫链的状态，与其他观测及状态无关。

