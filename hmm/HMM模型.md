# HMM模型

隐马尔科夫模型（HMM）可用于标注问题，在语音识别、NLP、生物信息（DNA）、模式识别等领域被实践证明是有效的算法。

## 1. HMM的定义

### 1.1 标记说明

HMM是关于时序的概率模型，描述一个过程：由一个隐藏的马尔科夫链随机生成不可观测的状态随机序列，同时每个状态会产生一个观测，进而形成观测随机序列。

由隐藏的马尔科夫随机生成的状态的序列，称为状态序列（state sequence）。每个状态生成一个观测，形成的观测的序列称为观测序列（observation sequence）。这两个序列的每个位置可以看作一个时刻。

![Image text](https://raw.github.com/Casey1203/ml-ease/master/img/hmm.png)

图中$z_1,z_2\ldots z_{n+1}$是状态序列，$x_1,x_2\ldots x_{n+1}$是观测序列。

HMM由初始状态分布$\pi$，状态转移概率分布$A$以及观测概率分布$B$确定。以三元符号表示，即
$$
\lambda=(A,B,\pi)
$$
接着，定义$Q$是所有可能的状态集合，$N$是可能的状态数。
$$
Q=\{q_1,q_2,\ldots,q_N\}
$$
定义$V$是可能的观测的集合，$M$是可能的观测数。
$$
V=\{v_1,v_2,\ldots,v_M\}
$$
接下来定义状态序列$I$和对应的观测序列$O$，它们的长度都为$T$
$$
I=\{i_1,i_2,\ldots,i_T\} \\
O=\{o_1,o_2,\ldots,o_T\}
$$
状态转移概率分布$A$是一个$N \times N$的矩阵，即$A=\left[a_{ij}\right]_{N\times N}$

其中，$a_{ij}=P(i_{t+1}=q_j|i_t=q_i)$表示$t$时刻处于状态$q_i$的条件下，在$t+1$时刻下转移到了状态$q_j$的概率。

观测概率分布B是一个$N \times M$的矩阵，即$B=\left[b_{i,k}\right]_{N\times M}$

其中，$b_{ik}=b_{q_i}(v_k)=P(o_t=v_k|i_k=q_i)$表示在$t$时刻处于状态$q_i$的条件下，生成观测$v_k$的概率。

初始状态分布$\pi$是一个$N\times 1$的向量，其中$\pi_i=P(i_1=q_i)$表示在1时刻处于状态$q_i$的概率。

举个例子说明观测和状态：在做语音识别系统的时候，系统听到的是人发出的声音，严格来说系统看到的是声音的波形，这是观测。这个语音识别系统的目的是为了把人发出的声音识别成对应的文字，这个文字就是状态，即隐藏在波形背后对应的文字。

再举个例子，在做中文分词的工作时，系统看到的是一句话，则这句话就是观测。这句话里包含有词和字，系统要判断应该在哪个字后面切一刀，那么系统就要判断每个字是否为一个词的结尾，即这个字是否应该被切开，那是/否切开，这就是状态。



为了对$\lambda=(A,B,\pi)$有更加深刻的认识，下面举《统计学习方法》上的一个例子来说明。

假设有4个合资，每个盒子里都装有红白两种颜色的球，盒子里的红白球数目见下表。

![Image text](https://raw.github.com/Casey1203/ml-ease/master/img/hmm_eg10.1.png)

首先以等概率随机抽取一个盒子。接着从这个盒子中随机抽取一个球，记录颜色后放回。然后从当前盒子随机转移到下一个盒子，规则是：如果当前盒子是盒子1,那么下一个盒子一定是盒子2；如果当前盒子时盒子2或3,那么分别以概率0.4和0.6转移到左边或右边的盒子。如果当前的盒子是盒子4，那么各以0.5的概率停留在盒子4或转移到盒子3，确定完盒子后，再从里面随机抽取一个球，并记录颜色后放回。如此重复下去。

在这个例子中，有四个盒子，盒子对应着状态。因此状态集合
$$
Q=\{盒子1,盒子2,盒子3,盒子4\},\quad N=4
$$
球的颜色对应着观测，观测集合
$$
V=\{红,白\}, \quad M=2
$$
观测序列和状态序列的长度，取决于这样抽取球的次数重复了几次。

因此，初始概率分布
$$
\pi=(0.25,0.25,0.25,0.25)^T
$$
状态转移概率分布
$$
A= \left[
\begin{matrix}
0 & 1 & 0 & 0\\
0.4 &0 & 0.6 & 0\\
0 & 0.4 & 0 & 0.6\\
0 & 0 & 0.5 & 0.5
\end{matrix}
\right]
$$
观测概率分布为
$$
B=\left[
\begin{matrix}
0.5 & 0.5\\
0.3 & 0.7\\
0.6 & 0.4\\
0.8 & 0.2
\end{matrix}
\right]
$$


### 1.2 HMM的两个假设

1. 齐次马尔科夫性假设：假设隐藏的马尔科夫链在任意时刻$t$的状态，只依赖于其**前一时刻的状态**，与其他时刻的状态及观测无关，也与时刻$t$无关。

$$
P(i_t|i_{t-1},o_{t-1,\ldots,i_1,o_1})=P(i_t|i_{t-1}), \quad t=1,2,\ldots,T
$$



1. 观测独立性假设：假设任意时刻的观测，只依赖于**该时刻**的马尔科夫链的**状态**，与其他观测及状态无关。

$$
P(o_t|i_T,i_{T-1},o_{T-1},\ldots,i_{t+1},o_{t+1},i_t,o_t,i_{t-1},o_{t-1}\ldots,i_1,o_1)=P(o_t|i_t)
$$



### 1.3 HMM的3个基本问题

1. 概率计算问题：给定模型$\lambda={A,B,\pi}$和观测序列$O=(o_1,o_2,\ldots,o_T)$，计算在模型$\lambda$的控制下观测序列$O$出现的概率$P(O|\lambda)$。
2. 学习问题：已知观测序列$O=(o_1,o_2,\ldots,o_T)$，估计模型$\lambda=(A,B,\pi)$参数，使得在该模型下观测序列的概率$P(O|\lambda)$最大。$P(O|\lambda)$是似然函数，因此可以套用极大似然估计的方法来估计参数$\lambda$。
3. 预测问题：也称为解码。已知模型$\lambda=(A,B,\pi)$和观测序列$O=(o_1,o_2,\ldots,o_T)$，求对给定观测序列条件概率$P(I|O)$最大的状态序列$I=(i_1,i_2,\ldots,i_T)$，即给定观测序列，求最有可能的对应的状态序列$I$。

第一个问题，是计算概率的问题。以1.1小节末尾的例子来说，假设我重复取5次，得到的观测结果是
$$
O=(红，红，白，白，红)
$$
求得到这个观测结果的概率有多大。

第二个问题，在未知模型参数$\lambda$的时候，给定一个观测序列，找到能够使得看到这个观测序列的概率最大的模型参数。这个学习过程中，含有隐状态$I$，即挑选到的盒子序列，因此本质是EM算法的过程。

第三个问题，已知模型的参数$\lambda$（也可以认为是经过了第二个问题后，学到了一个参数$\lambda$ ），以及观测序列，想要知道最有可能得到这个观测序列的状态序列$I$。这其实就是分词的过程，给定一个训练好的HMM模型（$\lambda$），以及一句话（$O$），想要找到最合适的分词结果（$I$）。

## 2. 概率计算算法

### 2.1 直接计算法

给定模型$\lambda$和观测序列$O=(o_1,o_2,\ldots,o_T)$，计算$O$出现的概率$P(O|\lambda)$，直接按照概率公式计算，枚举出所有可能的状态序列$I=(i_1,i_2,\ldots,i_T)$，长度为$T$。然后求各状态序列$I$与观测序列$O=(o_1,o_2,\ldots,o_T)$的联合概率分布$P(O,I|\lambda)$，再把所有可能的状态序列积分掉，得到$P(O|\lambda)$。

$O$和$I$同时出现的联合概率$P(O,I|\lambda)=P(O|I,\lambda)P(I|\lambda)$。根据给定的参数$\lambda=(A,B,\pi)$，求$P(O|I,\lambda)$和$P(I|\lambda)$。
$$
P(I|\lambda)=\pi_{i_1}a_{i_1i_2}\ldots a_{i_ti_{t+1}}\ldots a_{i_{T-1}i_T}
$$
其中$a_{i_t}a_{i_{t+1}}$为状态从$i_t$转移到$i_{t+1}$的概率。
$$
P(O|I,\lambda)=b_{i_1}(o_1)b_{i_2}(o_2)\ldots b_{i_t}(o_t)\ldots b_{i_T}(o_T)
$$

其中$b_{i_t}(o_t)$为在状态$i_t$的情况下，观测到$o_t$的概率。
$$
\begin{aligned}
P(O,I|\lambda)&=P(O|I,\lambda)P(I|\lambda)\\
&= \pi_{i_1}b_{i_1}(o_1)a_{i_1i_2}b_{i_2}(o_2)\ldots a_{i_ti_{t+1}}b_{i_{t+1}}(o_{t+1})\ldots a_{i_{T-1}i_T}b_{i_T}(o_T)
\end{aligned}
$$
最后，因为我们不关心状态序列，因此要把$I$给积分掉，因此
$$
\begin{aligned}
P(O|\lambda)&=\sum_I{P(O,I|\lambda)}\\
&=\sum_{i_1,i_2,\ldots,i_T}{\pi_{i_1}b_{i_1}(o_1)a_{i_1i_2}b_{i_2}(o_2)\ldots a_{i_ti_{t+1}}b_{i_{t+1}}(o_{t+1})\ldots a_{i_{T-1}i_T}b_{i_T}(o_T)}
\end{aligned}
$$
注意，$\sum_{i_1,i_2,\ldots,i_T}$的含义是$\sum_{i_1}\sum_{i_2}\ldots\sum_{i_T}$，这里有$T$个$\sum$，每个$\sum$有$N$种情况，表示$N$种状态。因此$\sum_{i_1,i_2,\ldots,i_T}$的复杂度是$N^T$。同时$\sum_{i_1,i_2,\ldots,i_T}{\pi_{i_1}b_{i_1}(o_1)a_{i_1i_2}b_{i_2}(o_2)\ldots a_{i_ti_{t+1}}b_{i_{t+1}}(o_{t+1})\ldots a_{i_{T-1}i_T}b_{i_T}(o_T)}$这个连乘有$2T$个数，因此总体的复杂度是$O(TN^T)$，是很庞大的计算量，因此该算法在实际情况下是不可行的。

### 2.2 前向算法和后向算法（动态规划）

首先定义前向概率和后向概率。

**前向概率**：给定HMM的参数$\lambda$，定义到$t$时刻的部分观测序列为$o_1,o_2,\ldots,o_t$，且状态位于$q_i$，发生这样的事件的概率定义作前向概率
$$
\alpha_t(i)=P(o_1,o_2,\ldots,o_t,i_t=q_i|\lambda)
$$
这里的记号看起来可能比较混乱，再回顾一下，时间到$t$的观测序列是$O_{1,t}=(o_1,o_2,\ldots,o_t)$，同时状态序列为$I=(i_1,i_2,\ldots,i_t)$，状态的取值范围是$Q=\{q_1,q_2,\ldots,q_N\}$，这里仅考虑状态序列$I$中第$t$时刻的状态$i_t$取到了$Q$中的元素$q_i$。

**后向概率**：给定HMM的参数$\lambda$，定义在时刻$t$的状态为$q_i$的条件下，从$t+1$时刻到$T$时刻，观测到的部分观测序列$o_{t+1},o_{t+2},\ldots o_T$，定义发生这样的时间的概率为后向概率
$$
\beta_t(i)=P(o_{t+1},o_{t+2},\ldots,o_T|i_t=q_i,\lambda)
$$


![Image text](https://raw.github.com/Casey1203/ml-ease/master/img/前向-后向图示.png)

在这幅图中可以清楚的看到，第一行是状态序列，第二行是观测序列。图中的左半边，为观测到$(o_1,o_2,\ldots,o_t)$，同时状态$i_t$位于$q_i$，即图中黄色的点。图中的右半边，为给定了$i_t=q_i$的条件下，观测到了$o_{t+1},o_{t+2},\ldots o_T$的情况。

有了上面两个概率的定义，接下来可以介绍前向算法和后向算法了。

**前向算法**

初值：在$t=1$时刻的前向概率
$$
\alpha_1(i)=P(o_1,i_1=i|\lambda)=\pi_{i}b_{i}(o_1), \quad i=1,2,\ldots,N
$$
这个式子表明，在$t=1$时刻，状态位于$i$，且观测到的状态为$o_1$的概率，$\pi_i$为初始时刻下，选择状态$i$的概率，$b_i(o_1)$表示在状态$i$下，选择观测$o_1$的概率。

递推：对于$t=1,2,\ldots,T-1$，
$$
\alpha_{t+1}(i)=\left(\sum_{j=1}^N \alpha_t(j)a_{ji}\right)b_{i}(o_{t+1})
$$
这是前向概率的递推公式，要求第$t+1$时刻状态位于$i$，而$t$时刻位于什么状态可以不关心。假定时刻$t$位于状态$j$，只需要在$t+1$时刻将状态转移到$i$即可，因此这样的事件发生的概率为$\alpha_t(j)a_{ji}$，表示在时刻$t$观测到了$o_1,o_2,\ldots,o_t$并且时刻$t$处于状态$q_j$，而在时刻$t+1$到达状态$i$的联合概率。因为$t$时刻可以在任意一种状态，因此需要把$j$给积分掉，因此得到$\sum_{j=1}^N{\alpha_t(j)a_{ji}}$。由于前向概率的定义是在$t+1$时刻，还要看到观测$o_{t+1}$，因此还需要乘以$b_i(o_{t+1})$，表示第$t+1$时刻，从状态$i$得到观测$o_{t+1}$。

终止：有了递推公式，则可以计算$T$时刻的状态位于$i$，并且看到了观测$o_T$的概率$\alpha_T(i)$。由于我们并不关心最终的状态位于哪个状态，因此需要把$i$积分掉，因此
$$
P(O|\lambda)=\sum_{i=1}^N \alpha_T(i)=\sum_{i}{P(O,i_T=i|\lambda)}
$$

前向算法是基于“状态序列的路径结构”递推计算$P(O|\lambda)$的算法。具体为，在$t=1$时刻，计算$\alpha_1(i)$有$N$个值，分别表示$t=1$时刻位于$N$个状态的某一个。然后在计算下一个时刻$t+1$的状态的前向概率$\alpha_{t+1}(i)$时，有$N$个前向概率需要计算，均利用了前一个时刻$t$的$N$个前向状态$\alpha_t(j)$，因此相邻两次计算需要有$N^2$的复杂度。因为序列长度为$T$，因此需要执行$T$次这样相邻的递推计算，因此总体的复杂度为$O(TN^2)$。

下面给一个例子来运用前向算法

给定HMM模型$\lambda=(A,B,\pi)$，它们分别是
$$
\pi = \left( \begin{array} { l } { 0.2 } \\ { 0.4 } \\ { 0.4 } \end{array} \right) \quad A = \left[ \begin{array} { c c c } { 0.5 } & { 0.2 } & { 0.3 } \\ { 0.3 } & { 0.5 } & { 0.2 } \\ { 0.2 } & { 0.3 } & { 0.5 } \end{array} \right] \quad B = \left[ \begin{array} { c c } { 0.5 } & { 0.5 } \\ { 0.4 } & { 0.6 } \\ { 0.7 } & { 0.3 } \end{array} \right]
$$
状态集合是$Q=\{1,2,3\}$，观测集合是$V=\{红，白\}$，假设序列长度为$T=3$，观测到了$O=(红，白，红)$，用前向算法求$P(O|\lambda)$。

初值
$$
\begin{array} { l } { \alpha _ { 1 } ( 1 ) = \pi _ { 1 } b _ { 1  }(o _ { 1 }) = 0.2 \times 0.5 = 0.1 } \\ { \alpha _ { 1 } ( 2 ) = \pi _ { 2 } b _ { 2  }(o _ { 1 }) = 0.4 \times 0.4 = 0.16 } \\ { \alpha _ { 1 } ( 3 ) = \pi _ { 3 } b _ { 3  }(o _ { 1 }) = 0.4 \times 0.7 = 0.28 } \end{array}
$$
递推

$T=2$：
$$
\begin{array} { l } { \alpha _ { 2 } ( 1 ) = \left( \sum _ { j = 1 } ^ { N } \alpha _ { 1 } ( j ) a _ { j 1 } \right) b _ { 1 }(o _ { 2 } ) } \\ { = ( 0.1 \times 0.5 + 0.16 \times 0.3 + 0.28 \times 0.2 ) \times 0.5 } \\ { = 0.077 } \\
{\alpha_2(2) = \left( \sum_{j=1}^N \alpha_1(j)a_{j2}\right)b_2(o_2)}\\
=(0.1\times 0.2 + 0.16 \times 0.5 + 0.28 \times 0.3) \times 0.6 \\
= 0.1104\\
{\alpha_2(3) = \left( \sum_{j=1}^N \alpha_1(j)a_{j2}\right)b_3(o_2)}\\
=(0.1\times 0.3 + 0.16 \times 0.2 + 0.28 \times 0.5)\times 0.3 \\
= 0.0606
\end{array}
$$
$T=3$：
$$
\begin{array} { l } { \alpha _ { 3 } ( 1 ) = \left( \sum _ { j = 1 } ^ { N } \alpha _ { 2 } ( j ) a _ { j 1 } \right) b _ { 1 }(o _ { 3 } ) } \\ 
{ = ( 0.077 \times 0.5 + 0.1104 \times 0.3 + 0.0606 \times 0.2 ) \times 0.5 } \\ 
{ = 0.04187 } \\
{\alpha_3(2) = \left( \sum_{j=1}^N \alpha_2(j)a_{j2}\right)b_2(o_3)}\\
=(0.077 \times 0.2 + 0.1104 \times 0.5 + 0.0606 \times 0.3) \times 0.4 \\
= 0.03551\\
{\alpha_3(3) = \left( \sum_{j=1}^N \alpha_2(j)a_{j2}\right)b_3(o_3)}\\
=(0.077 \times 0.3 + 0.1104 \times 0.2 + 0.0606 \times 0.5)\times 0.7 \\
= 0.05284
\end{array}
$$
最终，$P(O|\lambda)=0.04187 + 0.03551 + 0.05284=0.13022$

**后向算法**

和前向算法的思路相反，后向算法先从时刻$T$开始。回顾后向概率的定义
$$
\beta_t(i)=P(o_{t+1},o_{t+2},\ldots,o_T|i_t=q_i,\lambda)
$$
初值：$t=T$时刻，$\beta_T(i)=1,\quad i=1,2,\ldots,N$，表示$T$时刻，状态位于$i$。由于后面已经没有观测了，因此对于一个只要前提，不要结论的概率等于1。

递推：对于$t=T-1,\ldots,1$